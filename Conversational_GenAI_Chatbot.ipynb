{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGQMN9lUyqUd",
        "outputId": "d810b89f-12f8-41df-d850-124bffab0f60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m904.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m396.2/396.2 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.7/150.7 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "#it is required to use an Gen-AI model so installing Google's gemini here\n",
        "!pip install -q langchain_google_genai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#required a framework so installing langchain\n",
        "!pip install -q langchain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHrpM4Bzy4ve",
        "outputId": "f981f066-ffe2-415c-a9c1-e9086bd2aab4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.0 MB\u001b[0m \u001b[31m773.4 kB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/1.0 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.4/1.0 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m0.9/1.0 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#langchain community is used in version2 of langchain for extended support of langchain framework\n",
        "!pip install -q langchain-community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfITLrV4y4yd",
        "outputId": "4a6b6327-a489-4bd8-f858-49b5d2cdeac7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain-core"
      ],
      "metadata": {
        "id": "C-8M2F_KwMb4"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#setting up the google api key\n",
        "import getpass\n",
        "import os\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter your Google AI API key: \")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBOOATt-y40x",
        "outputId": "5df3469f-abf8-4bda-ff95-cb58a24c8296"
      },
      "execution_count": 7,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your Google AI API key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#loading the genai model\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-pro\",\n",
        "    temperature=0,\n",
        "    convert_system_message_to_human=True)\n",
        "llm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIV00cNHy43N",
        "outputId": "774839cf-df0c-4dd1-9e7f-7f3407254c98"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatGoogleGenerativeAI(model='models/gemini-pro', temperature=0.0, client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x7df734729930>, async_client=<google.ai.generativelanguage_v1beta.services.generative_service.async_client.GenerativeServiceAsyncClient object at 0x7df734764370>, default_metadata=(), convert_system_message_to_human=True)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#checking the conectivity for the google geminipro\n",
        "llm.invoke(\"what is machine learning?\").content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "-_b9WQrQy48T",
        "outputId": "f1d08cdf-4390-4d93-86b3-b237e15545a0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_google_genai/chat_models.py:381: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'**Machine Learning (ML)**\\n\\nMachine learning is a subfield of artificial intelligence (AI) that enables computers to learn from data without explicit programming. It involves algorithms that can:\\n\\n**1. Learn from Data:**\\n* ML algorithms analyze large datasets to identify patterns, relationships, and insights.\\n* They can learn from structured data (e.g., tables), unstructured data (e.g., text, images), or a combination of both.\\n\\n**2. Make Predictions:**\\n* Once trained on data, ML models can make predictions or classifications on new, unseen data.\\n* For example, they can predict customer churn, identify fraudulent transactions, or diagnose medical conditions.\\n\\n**3. Improve Over Time:**\\n* ML algorithms can continuously learn and improve their performance as they receive more data.\\n* This allows them to adapt to changing environments and improve their accuracy over time.\\n\\n**Types of Machine Learning:**\\n\\n* **Supervised Learning:** Algorithms learn from labeled data, where the input and output are known.\\n* **Unsupervised Learning:** Algorithms learn from unlabeled data, where the output is not known.\\n* **Reinforcement Learning:** Algorithms learn through trial and error, receiving rewards or penalties for their actions.\\n\\n**Applications of Machine Learning:**\\n\\nML has a wide range of applications across various industries, including:\\n\\n* **Healthcare:** Disease diagnosis, drug discovery, personalized medicine\\n* **Finance:** Fraud detection, risk assessment, investment analysis\\n* **Retail:** Product recommendations, customer segmentation, inventory management\\n* **Manufacturing:** Predictive maintenance, quality control, process optimization\\n* **Transportation:** Self-driving cars, traffic optimization, route planning\\n\\n**Benefits of Machine Learning:**\\n\\n* **Automation:** ML can automate tasks that are repetitive or require human expertise.\\n* **Improved Decision-Making:** ML models can provide insights and predictions that help businesses make better decisions.\\n* **Increased Efficiency:** ML can streamline processes and improve operational efficiency.\\n* **Personalized Experiences:** ML can tailor products, services, and recommendations to individual users.\\n* **Innovation:** ML drives innovation by enabling new applications and solving complex problems.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#in order to maintain the conversation history and memory(state of the conversation) we are importing few necessary libraries\n",
        "from langchain_core.chat_history import BaseChatMessageHistory,InMemoryChatMessageHistory\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n"
      ],
      "metadata": {
        "id": "YxTmMjXmy4_S"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating the session id to store the session details\n",
        "store = {}\n",
        "def get_session_history(session_id:str)->BaseChatMessageHistory:\n",
        "  if session_id not in store:\n",
        "    store[session_id]=InMemoryChatMessageHistory()\n",
        "  return store[session_id]"
      ],
      "metadata": {
        "id": "gUIVikNny5Bh"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#configuring the session ID\n",
        "config = {\"configurable\":{\"session_id\":\"first_chat\"}}"
      ],
      "metadata": {
        "id": "SV5qcTI0N-Cd"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_memory = RunnableWithMessageHistory(llm,get_session_history)"
      ],
      "metadata": {
        "id": "dNOfVkR9y5Dc"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#all the data will be stored inside the first_chat and if anything required apart from this session , configure another session id\n",
        "model_memory.invoke(\"Hello, my name is karthik?\",config=config).content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "PbWADAjey5Fd",
        "outputId": "e44e771e-ea8c-42b8-c8aa-8df015dda1d1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_google_genai/chat_models.py:381: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Hello Karthik, it's nice to meet you.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_memory.invoke(\"whats my name?\",config=config).content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "i_r4UkEyy5Im",
        "outputId": "9a87d10a-352d-4963-87d8-88851b19fdf9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_google_genai/chat_models.py:381: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Your name is Karthik.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# to see the stored session details in the store variable\n",
        "store"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lAkEMpJy5Lj",
        "outputId": "ff2599bc-70d8-4914-fc35-d109a85c979b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'first_chat': InMemoryChatMessageHistory(messages=[HumanMessage(content='Hello, my name is karthik?'), AIMessage(content=\"Hello Karthik, it's nice to meet you.\", response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-0125ea48-ed80-4751-bc7f-e96eb61c6d57-0', usage_metadata={'input_tokens': 9, 'output_tokens': 12, 'total_tokens': 21}), HumanMessage(content='whats my name?'), AIMessage(content='Your name is Karthik.', response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-d95e68bb-4546-4c39-8030-11726de15b91-0', usage_metadata={'input_tokens': 27, 'output_tokens': 6, 'total_tokens': 33})])}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder"
      ],
      "metadata": {
        "id": "PcKS-Qtwy5OO"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\",\"you are a helpful AI conversational chatbot, answer all the questions upto your knowledge, dont make things up.\"),\n",
        "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
        "\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "j_StcVSLy5QX"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = prompt | llm"
      ],
      "metadata": {
        "id": "PtJNJ16Vy5Sx"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain.invoke({\"chat_history\":[\"my name is karthik\"]}).content"
      ],
      "metadata": {
        "id": "716Rcfi2y5VG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "3c0d8b24-7da0-4afe-990a-806acd225301"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_google_genai/chat_models.py:381: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hello Karthik, I am a helpful AI conversational chatbot. I will do my best to answer all your questions to the best of my knowledge. However, please note that I am still under development and may not be able to answer all questions perfectly. If you have any questions, please feel free to ask.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "memory_model = RunnableWithMessageHistory(chain,get_session_history)"
      ],
      "metadata": {
        "id": "Tibbh3mny5XU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\"configurable\":{\"session_id\":\"second_chat\"}}"
      ],
      "metadata": {
        "id": "Aura9AzPyohV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_memory.invoke(\"what is deep learning?\",config=config).content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "KGGWot_Kyoem",
        "outputId": "1cf4dc36-7130-4695-96a3-27cce9085f03"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_google_genai/chat_models.py:381: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Deep learning is a type of machine learning that uses artificial neural networks to learn from data. Neural networks are inspired by the human brain and are able to learn complex patterns and relationships in data. Deep learning has been used to achieve state-of-the-art results in a wide range of tasks, including image recognition, natural language processing, and speech recognition.\\n\\nHere is a more detailed explanation of how deep learning works:\\n\\n* **Artificial neural networks** are made up of layers of interconnected nodes, or neurons. Each neuron takes in a set of inputs and produces an output. The output of one neuron can be the input to another neuron, and so on.\\n* **Deep learning networks** are made up of multiple layers of neurons. The first layer of neurons takes in the raw data, and each subsequent layer learns more complex features from the data.\\n* **Deep learning networks** are trained on large datasets. During training, the network learns to adjust its weights and biases so that it can make accurate predictions on new data.\\n\\nDeep learning has been used to achieve state-of-the-art results in a wide range of tasks, including:\\n\\n* **Image recognition**\\n* **Natural language processing**\\n* **Speech recognition**\\n* **Machine translation**\\n* **Medical diagnosis**\\n* **Financial forecasting**\\n\\nDeep learning is a powerful tool that can be used to solve a wide range of problems. As the amount of data available continues to grow, deep learning is likely to become even more important in the future.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_memory.invoke(\"what is 2+2?\",config=config).content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "piHBWUa_yob0",
        "outputId": "0c1de491-62f5-43f2-cf79-492b7104da18"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_google_genai/chat_models.py:381: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2 + 2 = 4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_memory.invoke(\"is the previous math question related to addition or substraction?\",config=config).content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "3HuEzB3eyoZE",
        "outputId": "9a87cc25-9806-4d2c-a4a2-d8ed576af43a"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_google_genai/chat_models.py:381: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The previous math question, 2 + 2, is related to **addition**.\\n\\nAddition is a mathematical operation that combines two or more numbers to get their sum. In the case of 2 + 2, the sum is 4.\\n\\nSubtraction, on the other hand, is a mathematical operation that takes one number away from another. For example, 4 - 2 = 2.\\n\\nI hope this helps!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "store"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9WXWxjAyoOO",
        "outputId": "db04d709-0922-4cd5-9995-84953800f172"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'first_chat': InMemoryChatMessageHistory(messages=[HumanMessage(content='Hello, my name is karthik?'), AIMessage(content=\"Hello Karthik, it's nice to meet you.\", response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-0125ea48-ed80-4751-bc7f-e96eb61c6d57-0', usage_metadata={'input_tokens': 9, 'output_tokens': 12, 'total_tokens': 21}), HumanMessage(content='whats my name?'), AIMessage(content='Your name is Karthik.', response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-d95e68bb-4546-4c39-8030-11726de15b91-0', usage_metadata={'input_tokens': 27, 'output_tokens': 6, 'total_tokens': 33}), HumanMessage(content='what is deep learning?'), AIMessage(content='Deep learning is a type of machine learning that uses artificial neural networks to learn from data. Neural networks are inspired by the human brain and are able to learn complex patterns and relationships in data. Deep learning has been used to achieve state-of-the-art results in a wide range of tasks, including image recognition, natural language processing, and speech recognition.\\n\\nHere is a more detailed explanation of how deep learning works:\\n\\n* **Artificial neural networks** are made up of layers of interconnected nodes, or neurons. Each neuron takes in a set of inputs and produces an output. The output of one neuron can be the input to another neuron, and so on.\\n* **Deep learning networks** are made up of multiple layers of neurons. The first layer of neurons takes in the raw data, and each subsequent layer learns more complex features from the data.\\n* **Deep learning networks** are trained on large datasets. During training, the network learns to adjust its weights and biases so that it can make accurate predictions on new data.\\n\\nDeep learning has been used to achieve state-of-the-art results in a wide range of tasks, including:\\n\\n* **Image recognition**\\n* **Natural language processing**\\n* **Speech recognition**\\n* **Machine translation**\\n* **Medical diagnosis**\\n* **Financial forecasting**\\n\\nDeep learning is a powerful tool that can be used to solve a wide range of problems. As the amount of data available continues to grow, deep learning is likely to become even more important in the future.', response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-49278180-6547-4051-9607-d4e2e15d2a10-0', usage_metadata={'input_tokens': 40, 'output_tokens': 313, 'total_tokens': 353}), HumanMessage(content='what is 2+2?'), AIMessage(content='2 + 2 = 4', response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-12354a09-aeab-46e9-a3fe-d77a4d496a6a-0', usage_metadata={'input_tokens': 362, 'output_tokens': 7, 'total_tokens': 369}), HumanMessage(content='is the previous math question related to addition or substraction?'), AIMessage(content='The previous math question, 2 + 2, is related to **addition**.\\n\\nAddition is a mathematical operation that combines two or more numbers to get their sum. In the case of 2 + 2, the sum is 4.\\n\\nSubtraction, on the other hand, is a mathematical operation that takes one number away from another. For example, 4 - 2 = 2.\\n\\nI hope this helps!', response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-efc2079f-0f91-48b0-a16c-2fba4f80fdcc-0', usage_metadata={'input_tokens': 384, 'output_tokens': 89, 'total_tokens': 473})])}"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SqGIszefzkhB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}